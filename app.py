import streamlit as st
import torch
import cv2
import os
from pathlib import Path
from PIL import Image
import numpy as np
import tempfile
import matplotlib.pyplot as plt
from collections import defaultdict

# é…ç½®Streamlit
st.set_page_config(
    page_title="é¦™è•‰æˆç†Ÿåº¦æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("ğŸŒ é¦™è•‰æˆç†Ÿåº¦æ£€æµ‹ç³»ç»Ÿ")
st.write("ä½¿ç”¨YOLOv8æ¨¡å‹å’Œé¢œè‰²ç‰¹å¾åˆ†ææ£€æµ‹é¦™è•‰çš„æˆç†Ÿåº¦")

# ä¾§è¾¹æ 
st.sidebar.title("æ¨¡å‹è®¾ç½®")
model_path = st.sidebar.text_input("æ¨¡å‹è·¯å¾„", value="banana_detection_yolov8_final.pt")
confidence_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.5, step=0.05)
use_color_analysis = st.sidebar.checkbox("å¯ç”¨é¢œè‰²ç‰¹å¾åˆ†æ", value=True)

# è°ƒè¯•é€‰é¡¹
st.sidebar.title("è°ƒè¯•é€‰é¡¹")
show_debug_info = st.sidebar.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=False)
enhance_contrast = st.sidebar.checkbox("å¢å¼ºå¯¹æ¯”åº¦", value=True)
low_confidence_mode = st.sidebar.checkbox("ä½ç½®ä¿¡åº¦æ¨¡å¼", value=False,
                                          help="é™ä½æ£€æµ‹é˜ˆå€¼ï¼Œæé«˜æ£€æµ‹ç‡ä½†å¯èƒ½å¢åŠ è¯¯æ£€")

st.sidebar.markdown("---")
st.sidebar.markdown("### å…³äºé¢œè‰²åˆ†æ")
st.sidebar.info("""
é¢œè‰²åˆ†æåŠŸèƒ½é€šè¿‡åˆ†æå›¾åƒä¸­é»„è‰²ã€ç»¿è‰²å’Œæ£•è‰²åŒºåŸŸçš„ç›¸å¯¹æ¯”ä¾‹æ¥è¾…åŠ©åˆ¤æ–­é¦™è•‰çš„æˆç†Ÿåº¦ï¼š

- **æœªæˆç†Ÿ (unripe)**: ç»¿è‰²åŒºåŸŸæ¯”ä¾‹ > 0.4
- **æˆç†Ÿ (ripe)**: é»„è‰²åŒºåŸŸæ¯”ä¾‹ > 0.5 ä¸”æ€»é¦™è•‰é¢œè‰²æ¯”ä¾‹ > 0.3
- **è¿‡ç†Ÿ (overripe)**: æ£•è‰²åŒºåŸŸæ¯”ä¾‹ > 0.2 ä¸”é»„è‰²åŒºåŸŸæ¯”ä¾‹ > 0.3
- **è…çƒ‚ (rotten)**: æ£•è‰²åŒºåŸŸæ¯”ä¾‹ > 0.4

å½“é¢œè‰²åˆ†æç½®ä¿¡åº¦ > 0.6 æ—¶ï¼Œä¼šä¼˜å…ˆè€ƒè™‘é¢œè‰²åˆ†æç»“æœã€‚
""")

st.sidebar.markdown("### å…³äºå½¢çŠ¶éªŒè¯")
st.sidebar.info("""
å½¢çŠ¶éªŒè¯åŠŸèƒ½é€šè¿‡è½®å»“åˆ†ææ¥åˆ¤æ–­å›¾åƒä¸­æ˜¯å¦åŒ…å«é¦™è•‰å½¢çŠ¶ï¼š

- é•¿å®½æ¯” > 1.5
- åœ†å½¢åº¦ < 0.7
- å‡¸æ€§ > 0.7

åªæœ‰åŒæ—¶é€šè¿‡é¢œè‰²åˆ†æå’Œå½¢çŠ¶éªŒè¯çš„å›¾åƒæ‰ä¼šè¢«è¯†åˆ«ä¸ºé¦™è•‰ã€‚
""")

# ç±»åˆ«æ ‡ç­¾
class_names = ['overripe', 'ripe', 'rotten', 'unripe']
class_descriptions = {
    'overripe': 'è¿‡ç†Ÿ',
    'ripe': 'æˆç†Ÿ',
    'rotten': 'è…çƒ‚',
    'unripe': 'æœªç†Ÿ'
}


# é¢œè‰²ç‰¹å¾æå–å‡½æ•°
def extract_color_features(image):
    """æå–å›¾åƒçš„é¢œè‰²ç‰¹å¾ï¼Œç”¨äºåŒºåˆ†é¦™è•‰æˆç†Ÿåº¦"""
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    lower_yellow = np.array([20, 100, 100])
    upper_yellow = np.array([30, 255, 255])
    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    yellow_ratio = np.sum(yellow_mask > 0) / (image.shape[0] * image.shape[1])

    lower_green = np.array([35, 40, 40])
    upper_green = np.array([85, 255, 255])
    green_mask = cv2.inRange(hsv, lower_green, upper_green)
    green_ratio = np.sum(green_mask > 0) / (image.shape[0] * image.shape[1])

    lower_brown = np.array([8, 60, 20])
    upper_brown = np.array([20, 255, 200])
    brown_mask = cv2.inRange(hsv, lower_brown, upper_brown)
    brown_ratio = np.sum(brown_mask > 0) / (image.shape[0] * image.shape[1])

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    brightness_mean = np.mean(gray)

    return {
        'yellow_ratio': yellow_ratio,
        'green_ratio': green_ratio,
        'brown_ratio': brown_ratio,
        'brightness_mean': brightness_mean,
        'mean_saturation': np.mean(hsv[:, :, 1])
    }


def contains_banana_shape(image, min_area=1000):
    """æ£€æŸ¥å›¾åƒæ˜¯å¦åŒ…å«é¦™è•‰å½¢çŠ¶çš„è½®å»“"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    binary = cv2.adaptiveThreshold(blurred, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 2)

    kernel = np.ones((3, 3), np.uint8)
    morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)

    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_area:
            continue

        perimeter = cv2.arcLength(contour, True)
        if perimeter == 0:
            continue

        circularity = 4 * np.pi * area / (perimeter * perimeter)
        rect = cv2.minAreaRect(contour)
        width, height = rect[1]
        aspect_ratio = max(width, height) / min(width, height) if min(width, height) > 0 else 0
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        convexity = area / hull_area if hull_area > 0 else 0

        if (aspect_ratio > 1.5 and
                circularity < 0.7 and
                convexity > 0.7 and
                area > min_area):
            return True
    return False


def classify_by_color_features(image_array):
    """åŸºäºé¢œè‰²ç‰¹å¾å¯¹é¦™è•‰è¿›è¡Œåˆ†ç±»"""
    if image_array is None:
        return "no_banana", 0.0, False

    has_shape = contains_banana_shape(image_array)
    features = extract_color_features(image_array)
    total_banana_colors = features['yellow_ratio'] + features['green_ratio'] + features['brown_ratio']

    if not has_shape and total_banana_colors < 0.3:
        return "no_banana", 0.0, has_shape

    shape_boost = 1.3 if has_shape else 1.0

    if features['green_ratio'] > 0.15 and features['yellow_ratio'] < 0.3:
        confidence = min(0.9, features['green_ratio'] * 3 * shape_boost)
        return "unripe", confidence, has_shape
    elif features['brown_ratio'] > 0.2:
        if features['brightness_mean'] < 100:
            confidence = min(0.9, features['brown_ratio'] * 3 * shape_boost)
            return "rotten", confidence, has_shape
        else:
            confidence = min(0.9, features['brown_ratio'] * 2.5 * shape_boost)
            return "overripe", confidence, has_shape
    elif features['yellow_ratio'] > 0.5 and total_banana_colors > 0.6:
        confidence = min(0.9, features['yellow_ratio'] * 2 * shape_boost)
        return "ripe", confidence, has_shape
    else:
        return "no_banana", 0.0, has_shape


def create_color_analysis_chart(image, features):
    """åˆ›å»ºé¢œè‰²ç‰¹å¾åˆ†æå›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    ax1.imshow(image_rgb)
    ax1.set_title("åŸå§‹å›¾åƒ")
    ax1.axis('off')

    feature_names = ['é»„è‰²', 'ç»¿è‰²', 'æ£•è‰²']
    feature_values = [features['yellow_ratio'], features['green_ratio'], features['brown_ratio']]
    colors = ['gold', 'green', 'brown']
    ax2.bar(feature_names, feature_values, color=colors)
    ax2.set_title('é¢œè‰²æ¯”ä¾‹åˆ†æ')
    ax2.set_ylim(0, max(0.5, max(feature_values) * 1.2))
    ax2.set_ylabel('æ¯”ä¾‹')

    plt.tight_layout()
    return fig


def process_detections(results, image_array, use_color_analysis=True, low_confidence_mode=False):
    """å¤„ç†æ£€æµ‹ç»“æœ"""
    detections = []
    for result in results:
        boxes = result.boxes
        if boxes is not None:
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = box.conf[0].cpu().numpy()
                cls = int(box.cls[0].cpu().numpy())
                class_name = class_names[cls]

                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': float(conf),
                    'class_id': cls,
                    'class_name': class_name
                })

    color_analysis_results = None
    if use_color_analysis:
        color_class, color_confidence, has_shape = classify_by_color_features(image_array)
        if color_class != "no_banana":
            color_analysis_results = {
                'class_name': color_class,
                'confidence': color_confidence,
                'has_shape': has_shape
            }

    final_detections = []
    if detections:
        for det in detections:
            final_class = det['class_name']
            final_confidence = det['confidence']

            if (color_analysis_results and
                    color_analysis_results['confidence'] > 0.6 and
                    color_analysis_results['has_shape']):
                if (det['class_name'] == "ripe" and color_analysis_results['class_name'] in ["unripe", "overripe"]) or \
                        (det['class_name'] == "rotten" and color_analysis_results['class_name'] == "overripe"):
                    final_class = color_analysis_results['class_name']
                    final_confidence = color_analysis_results['confidence']

            final_detections.append({
                'bbox': det['bbox'],
                'confidence': final_confidence,
                'class_id': det['class_id'],
                'class_name': final_class,
                'original_class': det['class_name'],
                'color_override': color_analysis_results and final_class != det['class_name']
            })
    else:
        if (color_analysis_results and
                color_analysis_results['confidence'] > 0.7 and
                color_analysis_results['has_shape']):
            final_detections.append({
                'bbox': None,
                'confidence': color_analysis_results['confidence'],
                'class_id': None,
                'class_name': color_analysis_results['class_name'],
                'original_class': None,
                'color_override': True
            })
        elif (low_confidence_mode and
              color_analysis_results and
              color_analysis_results['confidence'] > 0.5 and
              color_analysis_results['has_shape']):
            final_detections.append({
                'bbox': None,
                'confidence': color_analysis_results['confidence'],
                'class_id': None,
                'class_name': color_analysis_results['class_name'],
                'original_class': None,
                'color_override': True
            })

    return final_detections, color_analysis_results


def visualize_results(image_array, final_detections, class_descriptions):
    """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
    img = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
    for det in final_detections:
        if det['bbox']:
            x1, y1, x2, y2 = det['bbox']
            conf = det['confidence']
            class_name = det['class_name']
            color = (0, 255, 0) if det['color_override'] else (255, 0, 0)
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            label = f"{class_descriptions[class_name]}: {conf:.2f}"
            if det['color_override']:
                label += " (é¢œè‰²åˆ†æ)"
            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    return img


def enhance_image_contrast(image):
    """å¢å¼ºå›¾åƒå¯¹æ¯”åº¦"""
    if len(image.shape) == 3:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.merge((l, a, b))
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    else:
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(image)
    return enhanced


# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
if not os.path.exists(model_path):
    st.sidebar.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    st.info("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¸Šä¼ åˆ°ä»“åº“æ ¹ç›®å½•")
    st.stop()


# åŠ è½½æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜å’Œé”™è¯¯å¤„ç†ï¼‰
@st.cache_resource(ttl=3600)
def load_model(model_path):
    try:
        from ultralytics import YOLO
        model = YOLO(model_path)
        return model
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        st.info("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ")
        return None


model = load_model(model_path)
if model is None:
    st.stop()

# ä¸»ç•Œé¢
st.write("ä¸Šä¼ å›¾åƒæˆ–ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œæ£€æµ‹")

# åˆ›å»ºå…¨å±€è¾“å‡ºå ä½ç¬¦ï¼ˆå…³é”®ï¼é¿å…DOMå†²çªï¼‰
main_output = st.empty()
debug_output = st.empty()

# é€‰é¡¹å¡
tab1, tab2 = st.tabs(["ğŸ–¼ï¸ å›¾åƒä¸Šä¼ ", "ğŸ“¸ æ‘„åƒå¤´"])

with tab1:
    uploaded_file = st.file_uploader("é€‰æ‹©å›¾åƒæ–‡ä»¶", type=['jpg', 'jpeg', 'png', 'bmp'], key="image_uploader")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="ä¸Šä¼ çš„å›¾åƒ", use_column_width=True)

        if st.button("ğŸ” æ£€æµ‹é¦™è•‰æˆç†Ÿåº¦", key="image_detect"):
            with st.spinner("æ­£åœ¨æ£€æµ‹..."):
                # ä¿å­˜ä¸´æ—¶å›¾åƒ
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp:
                    image.save(tmp.name)
                    tmp_path = tmp.name

                try:
                    # è¯»å–å¹¶é¢„å¤„ç†å›¾åƒ
                    image_array = cv2.imread(tmp_path)
                    if enhance_contrast:
                        image_array = enhance_image_contrast(image_array)

                    # é¢„æµ‹
                    conf_threshold = 0.3 if low_confidence_mode else confidence_threshold
                    results = model.predict(tmp_path, conf=conf_threshold, verbose=False)

                    # å¤„ç†ç»“æœ
                    final_detections, color_analysis_results = process_detections(
                        results, image_array, use_color_analysis, low_confidence_mode
                    )

                    # æ¸…ç©ºå¹¶æ›´æ–°ä¸»è¾“å‡º
                    with main_output.container():
                        if final_detections:
                            result_img = visualize_results(image_array, final_detections, class_descriptions)
                            st.image(result_img, caption="âœ… æ£€æµ‹ç»“æœ", use_column_width=True)

                            st.subheader("æ£€æµ‹è¯¦æƒ…")
                            for i, det in enumerate(final_detections):
                                if det['bbox']:
                                    st.write(
                                        f"{i + 1}. **{class_descriptions[det['class_name']]}** (ç½®ä¿¡åº¦: {det['confidence']:.2f})")
                                    if det['color_override']:
                                        st.caption(
                                            f"â†’ åŸå§‹YOLOç»“æœ: {class_descriptions[det['original_class']]} (å·²è¢«é¢œè‰²åˆ†æè¦†ç›–)")
                                else:
                                    st.write(
                                        f"{i + 1}. **{class_descriptions[det['class_name']]}** (ä»…é¢œè‰²åˆ†æ, ç½®ä¿¡åº¦: {det['confidence']:.2f})")

                            # é¢œè‰²åˆ†æå›¾è¡¨
                            if use_color_analysis and color_analysis_results:
                                features = extract_color_features(image_array)
                                fig = create_color_analysis_chart(image_array, features)
                                st.pyplot(fig, clear_figure=True)

                                with st.expander("ğŸ“Š é¢œè‰²ç‰¹å¾è¯¦æƒ…", expanded=False):
                                    st.write(f"- é»„è‰²åŒºåŸŸæ¯”ä¾‹: {features['yellow_ratio']:.2%}")
                                    st.write(f"- ç»¿è‰²åŒºåŸŸæ¯”ä¾‹: {features['green_ratio']:.2%}")
                                    st.write(f"- æ£•è‰²åŒºåŸŸæ¯”ä¾‹: {features['brown_ratio']:.2%}")
                        else:
                            st.error("âŒ æœªæ£€æµ‹åˆ°é¦™è•‰")
                            if show_debug_info:
                                with debug_output.container():
                                    st.warning("å¼€å¯è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
                finally:
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)

with tab2:
    st.write("ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶æ£€æµ‹")
    st.info("ğŸ’¡ **ä½¿ç”¨æç¤º**: ç¡®ä¿é¦™è•‰æ¸…æ™°å¯è§ã€å…‰çº¿å……è¶³ã€å æ®ç”»é¢ä¸»è¦éƒ¨åˆ†")

    camera_image = st.camera_input("æ‹ç…§", key="camera_input")

    if camera_image is not None:
        image = Image.open(camera_image)
        st.image(image, caption="æ‘„åƒå¤´å›¾åƒ", use_column_width=True)

        if st.button("ğŸ” æ£€æµ‹é¦™è•‰æˆç†Ÿåº¦", key="camera_detect"):
            with st.spinner("æ­£åœ¨æ£€æµ‹..."):
                try:
                    # è½¬æ¢å›¾åƒ
                    image_np = np.array(image)
                    if len(image_np.shape) == 3 and image_np.shape[2] == 3:
                        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)

                    # é¢„å¤„ç†
                    processed_image = enhance_image_contrast(image_np) if enhance_contrast else image_np.copy()

                    # è°ƒæ•´å°ºå¯¸ï¼ˆå¦‚æœå¤ªå¤§ï¼‰
                    if max(processed_image.shape[:2]) > 1280:
                        scale = 1280 / max(processed_image.shape[:2])
                        new_size = (int(processed_image.shape[1] * scale), int(processed_image.shape[0] * scale))
                        processed_image = cv2.resize(processed_image, new_size)

                    # é¢„æµ‹
                    conf_threshold = 0.3 if low_confidence_mode else confidence_threshold
                    results = model.predict(processed_image, conf=conf_threshold, verbose=False)
                    final_detections, color_analysis_results = process_detections(
                        results, processed_image, use_color_analysis, low_confidence_mode
                    )

                    # å¦‚æœç¬¬ä¸€æ¬¡æ²¡æ£€æµ‹åˆ°ï¼Œå°è¯•æ›´ä½é˜ˆå€¼
                    if not final_detections:
                        results2 = model.predict(processed_image, conf=0.2, verbose=False)
                        final_detections, color_analysis_results = process_detections(
                            results2, processed_image, use_color_analysis, low_confidence_mode
                        )

                    # æ›´æ–°ä¸»è¾“å‡º
                    with main_output.container():
                        if final_detections:
                            # è°ƒæ•´åæ ‡å›åŸå§‹å°ºå¯¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            if processed_image.shape != image_np.shape:
                                scale_h = image_np.shape[0] / processed_image.shape[0]
                                scale_w = image_np.shape[1] / processed_image.shape[1]
                                for det in final_detections:
                                    if det['bbox']:
                                        x1, y1, x2, y2 = det['bbox']
                                        det['bbox'] = [
                                            int(x1 * scale_w),
                                            int(y1 * scale_h),
                                            int(x2 * scale_w),
                                            int(y2 * scale_h)
                                        ]

                            result_img = visualize_results(image_np, final_detections, class_descriptions)
                            st.image(result_img, caption="âœ… æ£€æµ‹ç»“æœ", use_column_width=True)

                            st.success("æ£€æµ‹æˆåŠŸï¼")
                            for i, det in enumerate(final_detections):
                                if det['bbox']:
                                    st.write(
                                        f"{i + 1}. **{class_descriptions[det['class_name']]}** (ç½®ä¿¡åº¦: {det['confidence']:.2f})")
                                    if det['color_override']:
                                        st.caption(
                                            f"â†’ åŸå§‹YOLOç»“æœ: {class_descriptions[det['original_class']]} (å·²è¢«é¢œè‰²åˆ†æè¦†ç›–)")
                                else:
                                    st.write(
                                        f"{i + 1}. **{class_descriptions[det['class_name']]}** (ä»…é¢œè‰²åˆ†æ, ç½®ä¿¡åº¦: {det['confidence']:.2f})")

                            if use_color_analysis and color_analysis_results:
                                features = extract_color_features(processed_image)
                                fig = create_color_analysis_chart(processed_image, features)
                                st.pyplot(fig, clear_figure=True)
                        else:
                            st.error("âŒ æœªæ£€æµ‹åˆ°é¦™è•‰")
                            if show_debug_info:
                                with debug_output.container():
                                    st.warning("å¼€å¯è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
                except Exception as e:
                    st.error(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# é¡µè„š
st.markdown("---")
st.caption("ä½¿ç”¨YOLOv8æ¨¡å‹å’Œé¢œè‰²ç‰¹å¾åˆ†æè®­ç»ƒçš„é¦™è•‰æˆç†Ÿåº¦æ£€æµ‹ç³»ç»Ÿ")